{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddc544d",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### 1. [Setup](#Setup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94147ab",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbf348",
   "metadata": {},
   "source": [
    "- imports\n",
    "- mkdirs\n",
    "- constants\n",
    "- variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117fcb6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb0bc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b17a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to import parquet engines\n",
    "try:\n",
    "    import pyarrow\n",
    "    PARQUET_ENGINE = 'pyarrow'\n",
    "except ImportError:\n",
    "    try:\n",
    "        import fastparquet\n",
    "        PARQUET_ENGINE = 'fastparquet'\n",
    "    except ImportError:\n",
    "        print(\"Warning: No parquet engine found. Installing pyarrow recommended.\")\n",
    "        print(\"Run: pip install pyarrow\")\n",
    "        PARQUET_ENGINE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd37eb2",
   "metadata": {},
   "source": [
    "## Mkdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('data/processed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedea4e8",
   "metadata": {},
   "source": [
    "## Consts and Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6b80fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = [\n",
    "    'AvgSurfT_inst',\n",
    "    # 'CanopInt_inst',\n",
    "    # 'LWdown_f_tavg',\n",
    "    # 'Psurf_f_inst',\n",
    "    # 'Qair_f_inst',\n",
    "    # 'SnowDepth_inst',\n",
    "    # 'SWdown_f_tavg',\n",
    "    # 'Tair_f_inst',\n",
    "    # 'TVeg_tavg',\n",
    "    # 'Wind_f_inst',\n",
    "    # 'Rainf_tavg'\n",
    "]  \n",
    "\n",
    "AGGREGATION = {\n",
    "    'Rainf_tavg': 'sum',        # Rain accumulates over time\n",
    "    'SnowDepth_inst': 'sum',    # Snow accumulation over time  \n",
    "    'CanopInt_inst': 'sum',     # Water accumulation over time\n",
    "    'Tair_f_inst': 'mean',      # Daily average temperature\n",
    "    'AvgSurfT_inst': 'mean',    # Daily average surface temperature\n",
    "    'Psurf_f_inst': 'mean',     # Daily average pressure\n",
    "    'Qair_f_inst': 'mean',      # Daily average humidity\n",
    "    'Wind_f_inst': 'mean',      # Daily average wind speed\n",
    "    'LWdown_f_tavg': 'mean',    # Daily average longwave radiation\n",
    "    'SWdown_f_tavg': 'mean',    # Daily average shortwave radiation\n",
    "    'TVeg_tavg': 'mean'         # Daily average transpiration\n",
    "}\n",
    "\n",
    "DATES = [\n",
    "    '2024_March',\n",
    "    '2024_April',\n",
    "    '2024_May',\n",
    "    '2024_June',\n",
    "    '2024_July',\n",
    "    '2024_Aug',\n",
    "    '2024_Sept',\n",
    "    '2024_Oct',\n",
    "    '2024_Nov',\n",
    "    '2024_Dec',\n",
    "    '2025_Jan',\n",
    "    '2025_Feb',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a87ae",
   "metadata": {},
   "source": [
    "# ReUsable Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f23f1",
   "metadata": {},
   "source": [
    "## Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc85e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_csv(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV file and return a pandas DataFrame.\"\"\"\n",
    "    file_path = Path('data/raw') / filename\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5d1913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_numpy(filename: str, subfolder: str) -> np.ndarray:\n",
    "    filename = f\"{filename}.csv\"\n",
    "    file_path = os.path.join('data', subfolder, filename)\n",
    "\n",
    "    data_as_list = []\n",
    "\n",
    "    with open(file_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        next(csv_reader)  # Skip header\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            data_as_list.append([float(val) for val in row])\n",
    "    \n",
    "    data = np.array(data_as_list)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddc8a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_parquet(arr, filename: str, subfolder: str):\n",
    "    filename = f\"{filename}.parquet\"\n",
    "    file_path = os.path.join('data', subfolder, filename)\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    df = pd.DataFrame(arr, columns=['year', 'month', 'day', 'longitude', 'latitude', 'value'])\n",
    "    df.to_parquet(file_path, index=False, engine=PARQUET_ENGINE)\n",
    "\n",
    "    print(f\"‚úÖ Data saved successfully!\")\n",
    "    print(f\"üìÅ Location: {file_path}\")\n",
    "    print(f\"ÔøΩÔøΩ Shape: {arr.shape[0]:,} rows √ó {arr.shape[1]} columns\")\n",
    "    print(f\"üíæ File size: {os.path.getsize(file_path) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265acc2",
   "metadata": {},
   "source": [
    "## Complex Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1dbf1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_3hourly_to_daily_pandas(arr, parameter):\n",
    "    # Convert array to pandas DataFrame\n",
    "    df = pd.DataFrame(arr, columns=['year', 'month', 'day', 'hour', 'longitude', 'latitude', 'value'])\n",
    "    \n",
    "    # Get the aggregation method for this parameter\n",
    "    agg_method = AGGREGATION.get(parameter, 'mean')  # Default to 'mean' if not found\n",
    "    \n",
    "    # Aggregate to daily using the appropriate method\n",
    "    daily_df = df.groupby(['longitude', 'latitude', 'year', 'month', 'day'])['value'].agg(agg_method).reset_index()\n",
    "    \n",
    "    # Convert back to numpy array\n",
    "    daily_arr = daily_df.values\n",
    "    \n",
    "    return daily_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6480a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_stats(arr):\n",
    "\n",
    "    print(f\"Total rows: {arr.shape[0]}\")\n",
    "    print(f\"Missing values in final column: {np.isnan(arr[:, -1]).sum()}\")\n",
    "    print(f\"Missing percentage: {np.isnan(arr[:, -1]).sum() / arr.shape[0] * 100:.2f}%\")\n",
    "\n",
    "    print(f\"Range: {arr[:, -1].min():.2f} to {arr[:, -1].max():.2f}\")\n",
    "    print(f\"Average: {arr[:, -1].mean():.2f}\")\n",
    "\n",
    "    print(f\"Longitude range: {arr[:, 4].min():.2f} to {arr[:, 4].max():.2f}\")\n",
    "    print(f\"Latitude range: {arr[:, 5].min():.2f} to {arr[:, 5].max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6e59e",
   "metadata": {},
   "source": [
    "# Raw Data Proccess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b4bc4",
   "metadata": {},
   "source": [
    "- Loop through and read monthly parameter CSVs\n",
    "- Run basic checks: missing data\n",
    "- Select data types so can be held as numpy array\n",
    "- Aggregate to daily\n",
    "- Concat monthlys into a single array\n",
    "- Sort by long, lat, year, month, day\n",
    "- Save as parqets in aggregated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c2440da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: AvgSurfT_inst\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_March\n",
      "AvgSurfT_inst_data_2024_March.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 206.82 to 349.63\n",
      "Average: 277.67\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "Monthly list now contains 1 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_April\n",
      "AvgSurfT_inst_data_2024_April.csv\n",
      "Total rows: 3638160\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 215.17 to 346.24\n",
      "Average: 283.46\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3638160, 7)\n",
      "Aggregated daily data: (454770, 6)\n",
      "Monthly list now contains 2 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_May\n",
      "AvgSurfT_inst_data_2024_May.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 223.41 to 345.40\n",
      "Average: 287.95\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "Monthly list now contains 3 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_June\n",
      "AvgSurfT_inst_data_2024_June.csv\n",
      "Total rows: 3638160\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 233.83 to 343.98\n",
      "Average: 292.42\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3638160, 7)\n",
      "Aggregated daily data: (454770, 6)\n",
      "Monthly list now contains 4 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_July\n",
      "AvgSurfT_inst_data_2024_July.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 248.17 to 345.72\n",
      "Average: 294.05\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "Monthly list now contains 5 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_Aug\n",
      "AvgSurfT_inst_data_2024_Aug.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 237.14 to 344.69\n",
      "Average: 293.05\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "Monthly list now contains 6 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_Sept\n",
      "AvgSurfT_inst_data_2024_Sept.csv\n",
      "Total rows: 3638160\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 223.88 to 347.08\n",
      "Average: 289.87\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3638160, 7)\n",
      "Aggregated daily data: (454770, 6)\n",
      "Monthly list now contains 7 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_Oct\n",
      "AvgSurfT_inst_data_2024_Oct.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 213.78 to 347.86\n",
      "Average: 284.38\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "Monthly list now contains 8 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_Nov\n",
      "AvgSurfT_inst_data_2024_Nov.csv\n",
      "Total rows: 3638160\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 206.80 to 347.52\n",
      "Average: 278.43\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3638160, 7)\n",
      "Aggregated daily data: (454770, 6)\n",
      "Monthly list now contains 9 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_Dec\n",
      "AvgSurfT_inst_data_2024_Dec.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 209.30 to 350.53\n",
      "Average: 274.20\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "Monthly list now contains 10 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2025_Jan\n",
      "AvgSurfT_inst_data_2025_Jan.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 205.20 to 349.71\n",
      "Average: 272.93\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "Monthly list now contains 11 datasets\n",
      "\n",
      "===\n",
      "\n",
      "date: 2025_Feb\n",
      "AvgSurfT_inst_data_2025_Feb.csv\n",
      "Total rows: 3395616\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 203.79 to 348.51\n",
      "Average: 273.96\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Original 3-hourly data: (3395616, 7)\n",
      "Aggregated daily data: (424452, 6)\n",
      "Monthly list now contains 12 datasets\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "Stacking 12 monthly datasets...\n",
      "Consolidated array shape: (5533035, 6)\n",
      "Total rows: 5,533,035\n",
      "Total columns: 6\n",
      "[-1.79500000e+02  6.65000000e+01  2.02400000e+03  3.00000000e+00\n",
      "  1.00000000e+00  2.40669425e+02]\n",
      "Total rows: 5533035\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 207.60 to 324.24\n",
      "Average: 283.58\n",
      "Longitude range: 1.00 to 31.00\n",
      "Latitude range: 207.60 to 324.24\n",
      "‚úÖ Data saved successfully!\n",
      "üìÅ Location: data/daily/AvgSurfT_inst.parquet\n",
      "ÔøΩÔøΩ Shape: 5,533,035 rows √ó 6 columns\n",
      "üíæ File size: 38.22 MB\n"
     ]
    }
   ],
   "source": [
    "for parameter in PARAMS:\n",
    "    print(f'Parameter: {parameter}')\n",
    "\n",
    "    monthly = []\n",
    "\n",
    "    for date in DATES:\n",
    "        print(f\"\\n===\\n\")\n",
    "\n",
    "        # File to be processed:\n",
    "        filename = f\"{parameter}_data_{date}\"\n",
    "        print(f\"date: {date}\")\n",
    "        print(filename + '.csv')\n",
    "\n",
    "        # Load CSV to numpy array:\n",
    "        try:\n",
    "            arr = read_csv_to_numpy(filename, 'raw')\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        # Basic stats/checks:\n",
    "        print_basic_stats(arr)\n",
    "\n",
    "        # Aggregation from 3hourly to daily:\n",
    "        daily_arr_numpy = aggregate_3hourly_to_daily_pandas(arr, parameter)\n",
    "        print(f\"Original 3-hourly data: {arr.shape}\")\n",
    "        print(f\"Aggregated daily data: {daily_arr_numpy.shape}\")\n",
    "\n",
    "        # Add to monthly list\n",
    "        monthly.append(daily_arr_numpy)\n",
    "        print(f\"Monthly list now contains {len(monthly)} datasets\")\n",
    "    \n",
    "    print(f\"\\n===\\n\")\n",
    "\n",
    "    if monthly:\n",
    "        print(f\"\\nStacking {len(monthly)} monthly datasets...\")\n",
    "    \n",
    "        # Stack all monthly arrays vertically (one on top of the other)\n",
    "        consolidated_arr = np.vstack(monthly)\n",
    "        \n",
    "        print(f\"Consolidated array shape: {consolidated_arr.shape}\")\n",
    "        print(f\"Total rows: {consolidated_arr.shape[0]:,}\")\n",
    "        print(f\"Total columns: {consolidated_arr.shape[1]}\")\n",
    "\n",
    "        print(consolidated_arr[0])\n",
    "\n",
    "        # Basic stats/checks:\n",
    "        print_basic_stats(consolidated_arr)\n",
    "\n",
    "        save_as_parquet(consolidated_arr, parameter, 'daily')\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
