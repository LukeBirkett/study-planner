{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddc544d",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### 1. [Setup](#Setup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94147ab",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbf348",
   "metadata": {},
   "source": [
    "- imports\n",
    "- mkdirs\n",
    "- constants\n",
    "- variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117fcb6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb0bc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b17a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to import parquet engines\n",
    "try:\n",
    "    import pyarrow\n",
    "    PARQUET_ENGINE = 'pyarrow'\n",
    "except ImportError:\n",
    "    try:\n",
    "        import fastparquet\n",
    "        PARQUET_ENGINE = 'fastparquet'\n",
    "    except ImportError:\n",
    "        print(\"Warning: No parquet engine found. Installing pyarrow recommended.\")\n",
    "        print(\"Run: pip install pyarrow\")\n",
    "        PARQUET_ENGINE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd37eb2",
   "metadata": {},
   "source": [
    "## Mkdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('data/processed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedea4e8",
   "metadata": {},
   "source": [
    "## Consts and Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6b80fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = [\n",
    "    # 'AvgSurfT_inst',\n",
    "    # 'CanopInt_inst',\n",
    "    # 'LWdown_f_tavg',\n",
    "    # 'Psurf_f_inst',\n",
    "    # 'Qair_f_inst',\n",
    "    # 'SnowDepth_inst',\n",
    "    # 'SWdown_f_tavg',\n",
    "    # 'Tair_f_inst',\n",
    "    # 'TVeg_tavg',\n",
    "    # 'Wind_f_inst',\n",
    "    'Rainf_tavg'\n",
    "]  \n",
    "\n",
    "AGGREGATION = {\n",
    "    'Rainf_tavg': 'sum',        # Rain accumulates over time\n",
    "    'SnowDepth_inst': 'sum',    # Snow accumulation over time  \n",
    "    'CanopInt_inst': 'sum',     # Water accumulation over time\n",
    "    'Tair_f_inst': 'mean',      # Daily average temperature\n",
    "    'AvgSurfT_inst': 'mean',    # Daily average surface temperature\n",
    "    'Psurf_f_inst': 'mean',     # Daily average pressure\n",
    "    'Qair_f_inst': 'mean',      # Daily average humidity\n",
    "    'Wind_f_inst': 'mean',      # Daily average wind speed\n",
    "    'LWdown_f_tavg': 'mean',    # Daily average longwave radiation\n",
    "    'SWdown_f_tavg': 'mean',    # Daily average shortwave radiation\n",
    "    'TVeg_tavg': 'mean'         # Daily average transpiration\n",
    "}\n",
    "\n",
    "DATES = [\n",
    "    '2024_March',\n",
    "    '2024_April',\n",
    "    # '2024_May',\n",
    "    # '2024_June',\n",
    "    # '2024_July',\n",
    "    # '2024_Aug',\n",
    "    # '2024_Sept',\n",
    "    # '2024_Oct',\n",
    "    # '2024_Nov',\n",
    "    # '2024_Dec',\n",
    "    # '2025_Jan',\n",
    "    # '2025_Feb',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a87ae",
   "metadata": {},
   "source": [
    "# ReUsable Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f23f1",
   "metadata": {},
   "source": [
    "## Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc85e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_csv(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV file and return a pandas DataFrame.\"\"\"\n",
    "    file_path = Path('data/raw') / filename\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5d1913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_numpy(filename: str, subfolder: str) -> np.ndarray:\n",
    "    filename = f\"{filename}.csv\"\n",
    "    file_path = os.path.join('data', subfolder, filename)\n",
    "\n",
    "    data_as_list = []\n",
    "\n",
    "    with open(file_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        next(csv_reader)  # Skip header\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            data_as_list.append([float(val) for val in row])\n",
    "    \n",
    "    data = np.array(data_as_list)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265acc2",
   "metadata": {},
   "source": [
    "## Complex Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dbf1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_3hourly_to_daily_pandas(arr, parameter):\n",
    "    # Convert array to pandas DataFrame\n",
    "    df = pd.DataFrame(arr, columns=['year', 'month', 'day', 'hour', 'longitude', 'latitude', 'value'])\n",
    "    \n",
    "    # Get the aggregation method for this parameter\n",
    "    agg_method = AGGREGATION.get(parameter, 'mean')  # Default to 'mean' if not found\n",
    "    \n",
    "    # Aggregate to daily using the appropriate method\n",
    "    daily_df = df.groupby(['longitude', 'latitude', 'year', 'month', 'day'])['value'].agg(agg_method).reset_index()\n",
    "    \n",
    "    # Convert back to numpy array\n",
    "    daily_arr = daily_df.values\n",
    "    \n",
    "    return daily_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6e59e",
   "metadata": {},
   "source": [
    "# Raw Data Proccess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b4bc4",
   "metadata": {},
   "source": [
    "- Loop through and read monthly parameter CSVs\n",
    "- Run basic checks: missing data\n",
    "- Select data types so can be held as numpy array\n",
    "- Aggregate to daily\n",
    "- Concat monthlys into a single array\n",
    "- Sort by long, lat, year, month, day\n",
    "- Save as parqets in aggregated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c2440da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: Rainf_tavg\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_March\n",
      "Rainf_tavg_data_2024_March.csv\n",
      "Total rows: 3759432\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 0.00 to 0.01\n",
      "Average: 0.00\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Rainf_tavg sum\n",
      "Original 3-hourly data: (3759432, 7)\n",
      "Aggregated daily data: (469929, 6)\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "date: 2024_April\n",
      "Rainf_tavg_data_2024_April.csv\n",
      "Total rows: 3638160\n",
      "Missing values in final column: 0\n",
      "Missing percentage: 0.00%\n",
      "Range: 0.00 to 0.01\n",
      "Average: 0.00\n",
      "Longitude range: -179.50 to 179.50\n",
      "Latitude range: -54.50 to 83.50\n",
      "Rainf_tavg sum\n",
      "Original 3-hourly data: (3638160, 7)\n",
      "Aggregated daily data: (454770, 6)\n",
      "\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for parameter in PARAMS:\n",
    "    print(f'Parameter: {parameter}')\n",
    "\n",
    "    monthly = []\n",
    "\n",
    "    for date in DATES:\n",
    "        print(f\"\\n===\\n\")\n",
    "\n",
    "        # File to be processed:\n",
    "        print(f\"date: {date}\")\n",
    "        filename = f\"{parameter}_data_{date}\"\n",
    "        print(filename + '.csv')\n",
    "\n",
    "        # Load CSV to numpy array:\n",
    "        try:\n",
    "            arr = read_csv_to_numpy(filename, 'raw')\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        # Basic statis/checks:\n",
    "        print(f\"Total rows: {arr.shape[0]}\")\n",
    "        print(f\"Missing values in final column: {np.isnan(arr[:, -1]).sum()}\")\n",
    "        print(f\"Missing percentage: {np.isnan(arr[:, -1]).sum() / arr.shape[0] * 100:.2f}%\")\n",
    "\n",
    "        print(f\"Range: {arr[:, -1].min():.2f} to {arr[:, -1].max():.2f}\")\n",
    "        print(f\"Average: {arr[:, -1].mean():.2f}\")\n",
    "\n",
    "        print(f\"Longitude range: {arr[:, 4].min():.2f} to {arr[:, 4].max():.2f}\")\n",
    "        print(f\"Latitude range: {arr[:, 5].min():.2f} to {arr[:, 5].max():.2f}\")\n",
    "\n",
    "        # Aggregation from 3hourly to daily:\n",
    "        daily_arr_numpy = aggregate_3hourly_to_daily_pandas(arr, parameter)\n",
    "        print(f\"Original 3-hourly data: {arr.shape}\")\n",
    "        print(f\"Aggregated daily data: {daily_arr_numpy.shape}\")\n",
    "\n",
    "        print(f\"\\n===\\n\")\n",
    "\n",
    "    # print(f'monthly: {monthly}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
