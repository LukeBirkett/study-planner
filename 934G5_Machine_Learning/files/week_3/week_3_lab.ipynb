{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kAEe8Q-7fIL9s5ibGq2Ih823nMLyDc4g","timestamp":1753120486991}],"collapsed_sections":["8Lm-0oqrCcpN","rxyl5fPn1cEU","kPvpMsQb3JN7","ZNQnWrTL1uFN","oHjsZ1d3NYCP","8UoIa45DE547","dlxoG_76etp6","ZPZlfnwlTsle","e1EuTj3KpxQo"],"authorship_tag":"ABX9TyOk6LgWKgQzoFaBRRkOqRyL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Learning outcomes"],"metadata":{"id":"8Lm-0oqrCcpN"}},{"cell_type":"markdown","source":["When you've worked through the exercise in this notebook, you'd have\n","\n","* built and evaluated SVM and logistic regression models using a standard software library;\n","\n","* explored selection of the best hyperparameters for your models."],"metadata":{"id":"KSrIkLSCCduL"}},{"cell_type":"markdown","source":["# Objectives"],"metadata":{"id":"rxyl5fPn1cEU"}},{"cell_type":"markdown","source":["\n","* To explore an existing dataset\n","> This week, we'll use a subset of the UK Met dataset. You can read more about the UK Met dataset here: https://rmets.onlinelibrary.wiley.com/doi/10.1002/gdj3.78. We will use the 60km-resolution data for 2010 to 2022.\n","\n","* To apply support vector machine (SVM) and logistic regression algorithms from Week 3 mini-videos to automatic detection of the number of days of ground frost based on other weather variables."],"metadata":{"id":"qCCRn5I21gF8"}},{"cell_type":"markdown","source":["# Section 1 - Explore the UK Met (60km, 2010-2022) dataset"],"metadata":{"id":"kPvpMsQb3JN7"}},{"cell_type":"markdown","source":["See the dataset on the Week 3 page for the module, on Canvas (see 'Week 3 Lab Dataset' on the page). The file is named c*urated_data_1month_2010-2022_nonans.csv*.\n","* What does each variable in the dataset represent?\n","* What is the distribution of the number of days of ground frost in the dataset? What of for the number of days of snow?\n","* What does this tell you about the data?\n","* What else can you tell about the data?\n"],"metadata":{"id":"DiO4BnO_-szF"}},{"cell_type":"markdown","source":["# Section 2 - Load the dataset\n","\n"],"metadata":{"id":"ZNQnWrTL1uFN"}},{"cell_type":"markdown","source":["\n","\n","1. You need to first download the data before you can get started. Download from the Week 3 page for the module, on Canvas (see 'Week 3 Lab Dataset' on the page). The file you download will be named *curated_data_1month_2010-2022_nonans.csv*.\n","\n","2. Then, use the file menu in Google Colab to upload the file to your Colab directory. Once upload is complete, you should be able to see the file on the listed contents of your Colab directory.\n","\n","3. You can now run the code in the cell below to load the data."],"metadata":{"id":"KXj3aE3e2dHy"}},{"cell_type":"code","source":["import csv\n","import numpy\n","\n","\n","\n","data_file_full_path = \"/content/curated_data_1month_2010-2022_nonans.csv\"\n","\n","data_as_list = []\n","\n","# load the dataset\n","with open(data_file_full_path) as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","\n","    row_count = 0\n","    for row in csv_reader:\n","\n","      if row_count > 0:\n","        data_as_list.append([float(val) for val in row])\n","      row_count += 1\n","data = numpy.array(data_as_list)\n","\n","# check its shape\n","print(\"\\n The dataset has shape: \"+str(data.shape))\n","\n","\n","# get features and labels from the data\n","# based on the objectives (see the Objectives section)\n","feat_col = [5, 6, 7, 8, 9, 10]\n","ground_frost_col = 4\n","\n","\n","feats = data[:, feat_col]\n","ground_frost_label = data[:, ground_frost_col]\n","\n","\n","\n","# take a peek\n","print(\"\\n A peek at the dataset features: \\n\"+str(feats))\n","print(\"\\n A peek at the ground frost labels: \\n\"+str(ground_frost_label))\n","\n"],"metadata":{"id":"0gFnB9nq4yWz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 3 - Split into training, validation, and test sets"],"metadata":{"id":"oHjsZ1d3NYCP"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","all_ids = numpy.arange(0, feats.shape[0])\n","\n","random_seed = 1\n","\n","# First randomly split the data into 70:30 to get the training set\n","train_set_ids, rem_set_ids = train_test_split(all_ids, test_size=0.3, train_size=0.7,\n","                                 random_state=random_seed, shuffle=True)\n","\n","\n","# Then further split the remaining data 50:50 into validation and test sets\n","val_set_ids, test_set_ids = train_test_split(rem_set_ids, test_size=0.5, train_size=0.5,\n","                                 random_state=random_seed, shuffle=True)\n","\n","\n","train_data = feats[train_set_ids, :]\n","train_ground_frost_labels = ground_frost_label[train_set_ids]\n","\n","\n","val_data = feats[val_set_ids, :]\n","val_ground_frost_labels = ground_frost_label[val_set_ids]\n","\n","\n","test_data = feats[test_set_ids, :]\n","test_ground_frost_labels = ground_frost_label[test_set_ids]\n"],"metadata":{"id":"pFYBM9RBSMDS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 4 - Scale the features"],"metadata":{"id":"8UoIa45DE547"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","\n","\n","scaler.partial_fit(train_data)\n","scaled_train_data = scaler.transform(train_data)\n","\n","\n","scaler.partial_fit(val_data)\n","scaled_val_data = scaler.transform(val_data)\n","\n","\n","scaler.partial_fit(test_data)\n","scaled_test_data = scaler.transform(test_data)\n"],"metadata":{"id":"kO6dfHuOE9UO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 5 - Train and evaluate a SVM regression model (with hyperparameter optimization)"],"metadata":{"id":"dlxoG_76etp6"}},{"cell_type":"markdown","source":["* Have a read of the documentation for the software library that implements the SVM for regression: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html.\n","\n","* Adapt the code below to optimize the regularization parameter C (aka 'box constraint')."],"metadata":{"id":"QOcX2yWFIgDc"}},{"cell_type":"code","source":["\n","from sklearn.svm import LinearSVR\n","from sklearn.metrics import mean_squared_error\n","import sys\n","\n","\n","\n","# train a SVM regression model\n","model_SVM = LinearSVR(random_state=random_seed, loss='squared_epsilon_insensitive')\n","model_SVM.fit(scaled_train_data, train_ground_frost_labels)\n","\n","# evaluate the trained model using the test set\n","test_pred_SVM = model_SVM.predict(scaled_test_data)\n","mse_SVM = mean_squared_error(test_ground_frost_labels, test_pred_SVM)\n","print('\\n The test mean squared error (MSE) is: '+str(mse_SVM))\n"],"metadata":{"id":"KFHU6GYrIZO2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 6 - Train and evaluate a LR classification model"],"metadata":{"id":"ZPZlfnwlTsle"}},{"cell_type":"markdown","source":["* Use the information from Section 1 to split the ground frost label values into 4 classes.\n","* Apply this to create classification labels for the labels in Section 2.\n","* Use the classification labels to train and evaluate a logistic regression model using the Scikit Learn library (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n"],"metadata":{"id":"gBxV3dKuUadG"}},{"cell_type":"markdown","source":["# Section 7 - Evaluate using other classification metrics"],"metadata":{"id":"e1EuTj3KpxQo"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","# F1 score similar to accuracy in that it ranges between 0 and 1\n","# We will look at this metric in Week 6\n","avg_f1_score_LR = f1_score(test_ground_frost_labels_class, test_pred_LR, average='macro')\n","f1_scores_LR = f1_score(test_ground_frost_labels_class, test_pred_LR, average=None)\n","print('\\n The F1 scores for each of the classes are: '+str(f1_scores_LR))\n","print('\\n The average F1 score is: '+str(avg_f1_score_LR))\n","print()\n","\n","# Confusion shows the misclassification\n","# We will look at this metric in Week 6\n","confusion_matrix_SVM = confusion_matrix(test_ground_frost_labels_class, test_pred_LR)\n","disp = ConfusionMatrixDisplay(confusion_matrix_SVM)\n","disp.plot()\n","plt.show()\n"],"metadata":{"id":"jQHmDopxb0q9"},"execution_count":null,"outputs":[]}]}