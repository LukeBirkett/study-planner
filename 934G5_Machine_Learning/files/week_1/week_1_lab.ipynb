{"cells":[{"cell_type":"markdown","source":["# Learning outcomes"],"metadata":{"id":"fatNy6SSaIGp"}},{"cell_type":"markdown","source":["When you've worked through the tasks and exercises in this notebook, you'd have\n","\n","* built a machine learning model using a standard software library;\n","* run experiments to explore effects of regularization and data augmentation."],"metadata":{"id":"tfzIAcpBaNYt"}},{"cell_type":"markdown","metadata":{"id":"eFg7aL7BqPex"},"source":["# Objectives\n","\n"]},{"cell_type":"markdown","source":["\n","* To introduce you to 2 of the main (Python-based) software libraries we'll be using throughout the module:\n","> 1. scikit-learn (https://scikit-learn.org/stable/) - one of the well-used machine learning libraries.\n","> 2. numpy (https://numpy.org/) -  a very common library for mathematical functions.\n","\n",">**Note**: It is your responsibility as a machine learning scientist to read documentations for any library function you use and to thoroughly understand what it is doing, if it validly serves your purpose, and which of its parameters you need to consider.\n","\n","* To see some of the basic components of machine learning first hand - training data, test (i.e. unseen) data, and machine learning model (with weights and biases being the primary parameters that specify a model for most types of models):\n",">1. Data - today, we'll use the Iris dataset. You can read more about it here: https://scikit-learn.org/stable/datasets/toy_dataset.html.\n",">2. Model - we'll explore linear regression, regularization, and augmentation, which we covered in the Week 1 mini-videos\n"],"metadata":{"id":"g8f4eGPFVUaz"}},{"cell_type":"markdown","metadata":{"id":"hsv7Ks_9qPe1"},"source":["# Section 1 - Set up imports and random number generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bibkBao6qPe1"},"outputs":[],"source":["%matplotlib inline\n","\n","import numpy\n","from sklearn import linear_model\n","from sklearn.metrics import mean_squared_error\n","import copy\n","\n","\n","# Set up the random number generator\n","rng =  numpy.random.default_rng()"]},{"cell_type":"markdown","source":["# Section 2 - Load the Iris dataset"],"metadata":{"id":"VHYf0-SDbXFO"}},{"cell_type":"code","source":["from sklearn import datasets\n","\n","iris_data, iris_labels = datasets.load_iris(return_X_y=True, as_frame=False)\n","\n","print(\"The dimensions of the Iris feature matrix\", iris_data.shape)"],"metadata":{"id":"MkpcYHZVbb_v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 3 - Explore the Iris dataset"],"metadata":{"id":"FRn04pDMbl8D"}},{"cell_type":"markdown","source":["* Read about the Iris dataset here: https://scikit-learn.org/stable/datasets/toy_dataset.html\n","* What type of labels does it have (real continuous or categorical)? What kind of machine learning task is this type of label suited to, i.e. classification or regression?\n","* What is the feature dimensionality of the dataset, i.e. the number of features?\n","* How many data instances are there? What is the distribution of instances across classes?\n","\n","\n","\n","---\n","\n","\n","* Select one of the features. What association does the selected feature have with the iris classes, with respect to differentiating between them (Hint - use a search engine to read about Iris Setosa, Iris Versicolour, and Iris Virginica plant)?\n","* What factors do you think limited the number of data instances per class?\n","* How do you think the data was collected? What implication would this have for real world deployment of a model for automatic detection of iris classes based on this dataset?\n","* How do you think it was labelled? What kind of challenge might this pose for collection of more training data (and labels) for automatic detection of iris classes?"],"metadata":{"id":"dbv3Jmu3bqdK"}},{"cell_type":"markdown","source":["# Section 4 - Split into training and test sets"],"metadata":{"id":"P4dgDkeob0fD"}},{"cell_type":"code","source":["\n","# Randomly split the data into 50:50 training:test sets\n","rand_inds = numpy.arange(iris_labels.shape[0],)\n","rng.shuffle(rand_inds)\n","split_point = int(0.5*iris_labels.shape[0])\n","\n","training_data_x = iris_data[rand_inds[0:split_point], :]\n","training_labels_y = iris_labels[rand_inds[0:split_point]]\n","test_data_x = iris_data[rand_inds[split_point:iris_labels.shape[0]], :]\n","test_labels_y = iris_labels[rand_inds[split_point:iris_labels.shape[0]]]\n","\n","print(\"Size of the training data:\", training_data_x.shape)\n","print(\"Size of the ttest data:\", test_data_x.shape)"],"metadata":{"id":"iJYJnYNyb1E_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SS3p1FHFqPe4"},"source":["# Section 5 - Train linear regression model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VG1xu2MqPe5"},"outputs":[],"source":["\n","print(training_data_x)\n","\n","# Train a linear regression model\n","lr_model = linear_model.LinearRegression()\n","lr_model.fit(training_data_x, training_labels_y)\n","print(\"\\nThe weight (w):\",  lr_model.coef_)\n","print(\"The bias (b):\",  lr_model.intercept_)\n","\n","# Check the performance of the model on the data used to train it\n","training_pred_y = lr_model.predict(training_data_x)\n","print(\"\\nMean squared error (error on training data): %.2f \" % mean_squared_error(training_labels_y, training_pred_y))\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x4cKOMKXqPe7"},"source":["# Section 6 - Explore reproducibility\n"]},{"cell_type":"markdown","source":["* Run Sections 4 and 5 code multiple times (e.g. 3 times) - each time, copy and paste your outputs (training data, weight, bias, mean squared error) somewhere so that you can compare outputs across the multiple runs. What do you notice? What is the implication, and how could you address it?"],"metadata":{"id":"KIPtsaBlfeDi"}},{"cell_type":"markdown","source":["# Section 7 - Explore the linear regression model"],"metadata":{"id":"XAmcTJuGTa7_"}},{"cell_type":"markdown","source":["\n","\n","*   Why are the 4 weights for the model?\n","*   Why is there one bias for the model?\n","\n"],"metadata":{"id":"qDMXHuw5TaFe"}},{"cell_type":"markdown","source":["# Section 8 - Explore the effects of L1 and L2 regularization"],"metadata":{"id":"eXBbTaUsWp9x"}},{"cell_type":"markdown","source":["*   Train and evaluate a linear regression model\n","  * See above examples; also see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n","*   Train and evaluate a linear regression model with L2 regularization\n","  * Set alpha to 0.5\n","  * See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)\n","*   Train and evaluate a linear regression model with L1 regularization\n","  * Set alpha to 0.5\n","  * See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)\n","*   What are the effects of regularization that you notice?\n","  * See Week 1 mini-videos\n","  * Hint - Compare the weights (and bias) and the errors.\n","\n","\n"],"metadata":{"id":"Kgt_0IwhW2HZ"}},{"cell_type":"markdown","source":["# Section 9 - Explore the effect of alpha on L1 and L2 regularization"],"metadata":{"id":"NS8-6nL6dzi3"}},{"cell_type":"markdown","source":["* Using your code in Section 8, compare the effect of multiple alpha values, e.g. alpha = 0.000000001, 0.0001, 0.1, on regularization."],"metadata":{"id":"avIg1Nmsd7hq"}},{"cell_type":"markdown","source":["# Section 10 - Explore the effect of data augmentation"],"metadata":{"id":"IDlB-YXs4ryU"}},{"cell_type":"markdown","source":["*   Train and evaluate a linear regression model\n","  * See above examples; also see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n","*   Train and evaluate a linear regression model with data augmentation applied to the training data\n","  * See Week 1 mini-videos\n","  * You could try adding randomly setting feature values to '-1'\n","  * You could try multiple augmentation intensities, e.g. probability of 0.01, 0.1, and 0.5 of setting to '-1'\n","*   Train and evaluate a linear regression model with another data augmentation applied to the training data\n","  * See Week 1 mini-videos\n","  * You could try randomly adding Gaussian noise to the data\n","  * You could try multiple augmentation intensities, e.g. Gaussian noise of standard deviation = 0.01, 0.1, and 0.5\n","*   What are the effects of augmentation that you notice?\n"],"metadata":{"id":"rEkGrdoJ4-ol"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"provenance":[{"file_id":"1TwyQnOCrbAB7xPr2YsW0a2M4WiAi87hK","timestamp":1752851218875}],"collapsed_sections":["fatNy6SSaIGp","eFg7aL7BqPex","hsv7Ks_9qPe1","VHYf0-SDbXFO","FRn04pDMbl8D","P4dgDkeob0fD","SS3p1FHFqPe4","x4cKOMKXqPe7","XAmcTJuGTa7_","eXBbTaUsWp9x","NS8-6nL6dzi3","IDlB-YXs4ryU"]}},"nbformat":4,"nbformat_minor":0}