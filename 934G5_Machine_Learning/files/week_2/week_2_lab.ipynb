{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1d13Yg9uJOwlYZGrZwnAXLKXDSHSjM_0Z","timestamp":1752853153668}],"collapsed_sections":["uZN4vNwdGDYJ","ZFxv8_7fU5b_","hwNfnB2EWiGG","3BkcCH1ynLY0","Iy9ViItU9bNm","yCS_gYcQ9omh","yYvcDmaC1E4Q","AK4ayJfatpMq","MjgsAEg7nBae","tiFdu9kB7CRQ","3OrlULuyGknx"],"authorship_tag":"ABX9TyPumyT2do71csx76Tn7v/nR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Learning outcomes"],"metadata":{"id":"uZN4vNwdGDYJ"}},{"cell_type":"markdown","source":["When you've worked through the exercise in this notebook, you'd have\n","\n","* built and evaluated tree-based and kNN models using a standard software library;\n","\n","* run experiments to explore effects of differing feature scales on machine learning models."],"metadata":{"id":"OLWS_IdRGFfJ"}},{"cell_type":"markdown","source":["# Objectives"],"metadata":{"id":"ZFxv8_7fU5b_"}},{"cell_type":"markdown","source":["\n","* To apply k-nearest neighbour (kNN) and Bagging algorithms from Week 2 mini-videos to classification of Iris plants based on petal and sepal sizes. This was the same dataset introduced in the Week 1 code notebook."],"metadata":{"id":"VzA6agO_VFY-"}},{"cell_type":"markdown","source":["# Section 1 - Load the Iris dataset"],"metadata":{"id":"hwNfnB2EWiGG"}},{"cell_type":"code","source":["from sklearn import datasets\n","\n","iris_data, iris_labels = datasets.load_iris(return_X_y=True, as_frame=False)\n","\n","print(\"The dimensions of the Iris feature matrix\", iris_data.shape)"],"metadata":{"id":"tf55cLnXmTpv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 2 - Split into training and test sets"],"metadata":{"id":"3BkcCH1ynLY0"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import numpy\n","\n","all_ids = numpy.arange(0, iris_data.shape[0])\n","\n","random_seed = 1\n","\n","# Rrandomly split the data into 50:50 to get the training set\n","train_set_ids, test_set_ids = train_test_split(all_ids, test_size=0.5, train_size=0.5,\n","                                 random_state=random_seed, shuffle=True)\n","\n","training_data = iris_data[train_set_ids, :]\n","training_labels = iris_labels[train_set_ids]\n","test_data = iris_data[test_set_ids, :]\n","test_labels = iris_labels[test_set_ids]\n","\n","print(\"Size of the training data:\", training_data.shape)\n","print(\"Size of the test data:\", test_data.shape)\n","print(\"A peek at the range of values of the training data features:\", training_data)"],"metadata":{"id":"r4w8BDBOnsbX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 3 - Train and evaluate a kNN model"],"metadata":{"id":"Iy9ViItU9bNm"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","model_kNN = KNeighborsClassifier(n_neighbors=5)\n","model_kNN.fit(training_data, training_labels)\n","test_predictions_kNN = model_kNN.predict(test_data)\n","\n","print(\"\\n What proportion of the kNN test predictions were correct? %.2f \" % accuracy_score(test_labels, test_predictions_kNN))"],"metadata":{"id":"UmAsAN76qZHs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 4 - Visually explore the data and predictions"],"metadata":{"id":"yCS_gYcQ9omh"}},{"cell_type":"markdown","source":["* Use plots of iris sepal and petal characteristics (their length and/or width) to explore how distinct the three iris classes are based on their sepals and petals.\n"],"metadata":{"id":"A4B8O50SEjVu"}},{"cell_type":"markdown","source":["# Section 5 - Explore the effect of the kNN hyperparameters"],"metadata":{"id":"yYvcDmaC1E4Q"}},{"cell_type":"markdown","source":["* Try different values of k, i.e. the number of nearest neighbours, e.g. k = 1, 2, 5, 10, 20. What effect of k do you notice?\n","* Try a different distance metric. See https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html."],"metadata":{"id":"iC5NmGl-1M8e"}},{"cell_type":"markdown","source":["# Section 6 - Train and evaluate a Bagging model"],"metadata":{"id":"AK4ayJfatpMq"}},{"cell_type":"code","source":["from sklearn.ensemble import BaggingClassifier\n","import math\n","\n","# Set the max number of features to be used to split each node for each tree\n","max_feats = int(math.sqrt(training_data.shape[1]))\n","\n","model_B = BaggingClassifier(n_estimators=100, max_features=max_feats, random_state=random_seed)\n","model_B.fit(training_data, training_labels)\n","test_predictions_B = model_B.predict(test_data)\n","\n","\n","print(\"\\n What proportion of the Bagging test predictions were correct? %.2f \" % accuracy_score(test_labels, test_predictions_B))"],"metadata":{"id":"kUylE51qeJRl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 7 - Explore the effect of the Bagging hyperparameters"],"metadata":{"id":"MjgsAEg7nBae"}},{"cell_type":"markdown","source":["* Try different numbers of base classifiers, i.e. trees, e.g. ntrees = 1, 10, 100, 1000. What effect of the number of trees do you notice?"],"metadata":{"id":"q3UOeYy9KwN-"}},{"cell_type":"markdown","source":["# Section 8 - Explore split into training and test sets"],"metadata":{"id":"tiFdu9kB7CRQ"}},{"cell_type":"markdown","source":["* How was the Iris dataset split into training and test sets? See Section 2.\n","* Randomly split the dataset into training and test sets such that the ratio of instances is 80:20.\n","* What is the effect on performance of the Bagging algorithm?"],"metadata":{"id":"lfdWPjAuTJmF"}},{"cell_type":"markdown","source":["# Section 9 - Train and evaluate the kNN and Bagging models with scaled features"],"metadata":{"id":"3OrlULuyGknx"}},{"cell_type":"markdown","source":["* Read the StandardScaler documentation (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Using the documentation above, compute scaled features from *iris_data* in Section 1 based on standard scaling.\n","\n","* Train and evaluate a kNN and a Bagging model with the scaled features.\n","\n","* What differences do you notice in the feature distribution and the results?"],"metadata":{"id":"ebVblgc9Glav"}}]}