{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjIgwH4mURxe"
   },
   "source": [
    "# Week 4: Naive Bayes Classification (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCv5KJOCURxf"
   },
   "source": [
    "### Overview\n",
    "This notebook builds on the activities in the previous notebooks on sentiment analysis.  In this lab, we will be putting everything together.  You will be focussing on the movie_review corpus us with a view to investigating:\n",
    "\n",
    "- Evaluation metrics for classifier performance\n",
    "- Which is the best classifier from a set of possibilities on a given test set\n",
    "- What is the impact of varying training data size? To what extent does increasing the quantity of training data improve classifier performance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PcLiXjQURxg"
   },
   "source": [
    "### Preliminaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1634372526692,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "WfXOB5bvCkYd",
    "outputId": "471f0303-6c58-4d55-9f67-665f8b503a2d"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LirziHXVURxh"
   },
   "source": [
    ">To access functionality defined in previous notebooks, copy the classes and functions defined in Week3Labs and Week4Labs into a `utils.py` file and then import it into the notebook.  There is a `utils.py` file included with these resources which you can update.  You should make sure that your classifier and ConfusionMatrix classes are defined in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1634372475303,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "V52nYgAzLJCh",
    "outputId": "88fb9beb-549e-4fed-f3f5-3413c5f9bcfd"
   },
   "outputs": [],
   "source": [
    "#uncomment on google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#you don't need this on jupyter notebook unless you want to import from a directory which is not the current working directory\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/NLE Notebooks 2021/Week4LabsSolutions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1634372479426,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "Zb62QpRpURxi"
   },
   "outputs": [],
   "source": [
    "#import code to setup training and testing data, wordlist classifiers and NB classifiers\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69GFXRKwURxz"
   },
   "source": [
    "### Evaluating a Naïve Bayes classifier on test data\n",
    "We are now ready to run our Naïve Bayes classifier on a set of test data. When we do this we want to return the accuracy of the classifier on that data, where accuracy is calculated as follows:\n",
    "\n",
    "$$\\frac{\\mbox{number of test documents that the classifier classifiers correctly}}\n",
    "{\\mbox{total number of test documents}}$$\n",
    "\n",
    "In order to compute this accuracy score, we need to give the classifier **labelled** test data.\n",
    "- This will be in the same format as the training data.\n",
    "\n",
    ">In the cell below, we set up 5 test documents in the class `weather` and 5 documents in the class `football`.\n",
    "\n",
    ">Run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1634372482218,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "wHdSTRXxURxz"
   },
   "outputs": [],
   "source": [
    "weather_sents_train = [\n",
    "    \"today it is raining\",\n",
    "    \"looking cloudy today\",\n",
    "    \"it is nice weather\",\n",
    "]\n",
    "\n",
    "football_sents_train = [\n",
    "    \"city looking good\",\n",
    "    \"advantage united\",\n",
    "]\n",
    "\n",
    "weather_data_train = [(FreqDist(sent.split()), \"weather\") for sent in weather_sents_train] \n",
    "football_data_train = [(FreqDist(sent.split()), \"football\") for sent in football_sents_train]\n",
    "train_data = weather_data_train + football_data_train\n",
    "\n",
    "weather_sents_test = [\n",
    "    \"the weather today is nice\",\n",
    "    \"it is raining cats and dogs\",\n",
    "    \"the weather here is wet\",\n",
    "    \"it was hot today\",\n",
    "    \"rain due tomorrow\",\n",
    "]\n",
    "\n",
    "football_sents_test = [\n",
    "    \"what a great goal that was\",\n",
    "    \"poor defending by the city center back\",\n",
    "    \"wow he missed a sitter\",\n",
    "    \"united are a shambles\",\n",
    "    \"shots raining down on the keeper\",\n",
    "]\n",
    "\n",
    "weather_data_test = [(FreqDist(sent.split()), \"weather\") for sent in weather_sents_test] \n",
    "football_data_test = [(FreqDist(sent.split()), \"football\") for sent in football_sents_test]\n",
    "test_data = weather_data_test + football_data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634372483140,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "2H2vYmrSURx2",
    "outputId": "bd4d76be-1faf-482a-eeea-dab5099eb4d1"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1634372483476,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "8PHd3ec_URx6",
    "outputId": "086bdce9-6a6b-42b7-e1d5-9cb4fd395d5f"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0qwxibFURx9"
   },
   "source": [
    "### Exercise 1\n",
    "Train the NB classifier that you developed earlier and then test it.\n",
    "Compute accuracy, precision, recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1634372487699,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "xacLM2MlURyD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1634372492658,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "SrK5dQnnK7-O",
    "outputId": "5cd3d0b7-79b9-435e-b052-c63d4456c7e6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejYzMjWmURyR"
   },
   "source": [
    "### Exercise 2\n",
    "Now, we want to run your NB classifier on a real problem - the classification of movie reviews as positive or negative.\n",
    "* generate a training and test split of the data for movie_reviews (see Lab 3_1 / 3_2)\n",
    "* train a nb_classifier on the training data\n",
    "* test it on the test data\n",
    "\n",
    "Compare the performance of your Naive Bayes classifier with the WordList classifiers that you developed last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1634372496065,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "HYqZwCU6URyR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKKAh-8iURyx"
   },
   "source": [
    "### NLTK NB Classifier\n",
    "Developing our own NB classifier is great for understanding how it works.  But, in practice, it is usually more convenient to use a standard one imported from a library.  NLTK provides a NB classifier (as do other libraries such as sklearn).  It can be imported and trained as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2726,
     "status": "ok",
     "timestamp": 1634372726702,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "1gK6rsS2K7-Q"
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "#note that the NaiveBayesClassifier.train() method is a class method which returns the classifier object.\n",
    "#this is different to ours and other classifiers which are first instantiated and then trained via an object method\n",
    "nltk_nb=NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVjXrwZ9K7-Q"
   },
   "source": [
    "This object also has a .classify_many() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1307,
     "status": "ok",
     "timestamp": 1634372730802,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "pOtEHLGXK7-R",
    "outputId": "74ff095f-55d9-4e9b-aab8-bc94b0164164"
   },
   "outputs": [],
   "source": [
    "nltk_nb.classify_many(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY46mVIZK7-R"
   },
   "source": [
    "### Exercise 3 \n",
    "\n",
    "Compare the performance of the NLTK NB classifier with the one that you wrote yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1634372736587,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "XX10y6jCK7-R",
    "outputId": "b355d926-5626-4f5e-915b-ac15eb32f6c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2jKE8hEK7-R"
   },
   "source": [
    "### Extension exercises\n",
    "* Investigate the impact of the amount of training data on the Naive Bayes classifiers.\n",
    "* Research what kind of event model is used by the NLTK NB classifier by default and whether / how this can be changed.  Does this impact the performance?\n",
    "* Find out about a NB classifier provided by a different library e.g., sklearn.  Can you apply this to the movie_review data set?\n",
    "* Find out about another machine learning method for classification (e.g., logistic regression).  Can you apply this to the movie_review data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3Ltl38HK7-S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "kCv5KJOCURxf"
   ],
   "name": "Lab_4_2-SOLUTIONS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
