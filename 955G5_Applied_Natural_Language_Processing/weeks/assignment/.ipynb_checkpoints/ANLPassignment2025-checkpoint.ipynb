{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2S8I2ny-ovS"
   },
   "source": [
    "# ANLP Assignment: Sentiment Classification\n",
    "\n",
    "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
    "\n",
    "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
    "\n",
    "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1gXQAZas-l9c"
   },
   "outputs": [],
   "source": [
    "candidateno=291065 #this MUST be updated to your candidate number so that you get a unique data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nk8JTP88A8vs",
    "outputId": "5ce22518-19d8-4c38-b8f9-13732a3c7a44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lukebirkett/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lukebirkett/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/lukebirkett/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "#preliminary imports\n",
    "\n",
    "#set up nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "#for setting up training and testing data\n",
    "import random\n",
    "\n",
    "#useful other tools\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify.api import ClassifierI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BHBkzAccCVaZ"
   },
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
    "    \"\"\"\n",
    "    Given corpus generator and ratio:\n",
    "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
    "\n",
    "    :param data: A corpus generator.\n",
    "    :param ratio: The proportion of training documents (default 0.7)\n",
    "    :return: a pair (tuple) of lists where the first element of the\n",
    "            pair is a list of the training data and the second is a list of the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    data = list(data)\n",
    "    n = len(data)\n",
    "    train_indices = random.sample(range(n), int(n * ratio))\n",
    "    test_indices = list(set(range(n)) - set(train_indices))\n",
    "    train = [data[i] for i in train_indices]\n",
    "    test = [data[i] for i in test_indices]\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "def get_train_test_data():\n",
    "\n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "\n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
    "\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N3LWwBYICPP"
   },
   "source": [
    "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HJLegkdPFUJA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of training data is 1400\n",
      "The amount of testing data is 600\n",
      "The representation of a single data item is below\n",
      "(['i', 'want', 'to', 'correct', 'what', 'i', 'wrote', ...], 'pos')\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "random.seed(candidateno)\n",
    "training_data,testing_data=get_train_test_data()\n",
    "print(\"The amount of training data is {}\".format(len(training_data)))\n",
    "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
    "print(\"The representation of a single data item is below\")\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Re-Useable Code and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(token_list: list, stop_words: list):\n",
    "    \"\"\"\n",
    "    Applies case normalization, removes numbers and punctuation, \n",
    "    and removes stopwords from a list of tokens.\n",
    "\n",
    "    Args:\n",
    "        token_list (list): The input list of tokens (strings).\n",
    "        stop_words (set/list): A collection of words to be removed (stopwords).\n",
    "\n",
    "    Returns:\n",
    "        list: The preprocessed list of tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_list = [\n",
    "        token.lower()\n",
    "        for token in token_list  \n",
    "        if token.isalpha()        # removes numbers and punctuation\n",
    "        and token.lower() not in stop_words  # remove tokens in stop_words (by keeping those not in stop_words)\n",
    "    ]\n",
    "    \n",
    "    return processed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating Positive and Negative Word Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbTq6eGv2XT2"
   },
   "source": [
    "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
    "\n",
    "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
    "\n",
    "c) **Explain** what you have done and why\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code (a & b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gvFu36xZ2XT5"
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "pos_freq_dist=FreqDist()\n",
    "neg_freq_dist=FreqDist()\n",
    "\n",
    "for rev,label in training_data:\n",
    "\n",
    "    # PREPROCESSING: case, number, punctuation, stopword\n",
    "    rev = preprocess_text(token_list=rev, stop_words=stop)\n",
    "\n",
    "    # FreqDist() data structure\n",
    "    if label == 'pos':\n",
    "        pos_freq_dist.update(rev) \n",
    "    elif label == 'neg':\n",
    "        neg_freq_dist.update(rev)\n",
    "    else: \n",
    "        print(\"unexpected class\")\n",
    "\n",
    "# IDENTIFY WORD DIFFERENTIAL BETWEEN CLASSSES\n",
    "all_words = set(pos_freq_dist.keys()) | set(neg_freq_dist.keys()) # all unique words\n",
    "\n",
    "word_counts = []\n",
    "\n",
    "for word in all_words:\n",
    "    pos_count = pos_freq_dist.get(word, 0)\n",
    "    neg_count = neg_freq_dist.get(word, 0)\n",
    "    difference = pos_count - neg_count\n",
    "    total = pos_count + neg_count\n",
    "    word_counts.append((word, difference, total))\n",
    "\n",
    "# IDENTIFY REVIEW DOMAIN STOP WORDS\n",
    "word_counts_copy = list(word_counts)\n",
    "word_counts_copy.sort(key=lambda item: item[2], reverse=True) # [2] = Total Corpus Count\n",
    "_domainStopWords = word_counts_copy[:5] # 5 most common review words\n",
    "domainStopWords = [word for word, diff, total in _domainStopWords]\n",
    "domain_stop_set = set(domainStopWords)\n",
    "\n",
    "# DROP DOMAIN WORDS FROM LIST\n",
    "final_word_counts = [word for word in word_counts if word[0] not in domain_stop_set]\n",
    "\n",
    "# SORY BY [1], THE CLASS/LABEL DIFFERENTIAL\n",
    "final_word_counts.sort(key=lambda item: item[1]) # low to high\n",
    "\n",
    "# COLLECT WORDS WITH THE LARGEST DIFFERENTIAL\n",
    "_negative_word_list = final_word_counts[:10] # first 10\n",
    "_positive_word_list = final_word_counts[-10:] # last 10\n",
    "\n",
    "_positive_word_list.sort(key=lambda item: item[1], reverse=True) # high to low\n",
    "\n",
    "negative_word_list = [word for word, diff, total in _negative_word_list]\n",
    "positive_word_list = [word for word, diff, total in _positive_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'movie', 'one', 'like', 'even']\n"
     ]
    }
   ],
   "source": [
    "print(domainStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JauTzY5N2XUB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad', 'plot', 'nothing', 'worst', 'script', 'stupid', 'boring', 'least', 'harry', 'supposed']\n"
     ]
    }
   ],
   "source": [
    "print(negative_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bad', -476, 998), ('plot', -244, 1040), ('nothing', -153, 555), ('worst', -139, 205), ('script', -127, 533), ('stupid', -114, 174), ('boring', -113, 195), ('least', -107, 447), ('harry', -105, 163), ('supposed', -105, 223)]\n"
     ]
    }
   ],
   "source": [
    "print(_negative_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['life', 'also', 'great', 'well', 'best', 'story', 'many', 'world', 'love', 'first']\n"
     ]
    }
   ],
   "source": [
    "print(positive_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('life', 329, 1113), ('also', 327, 1395), ('great', 263, 833), ('well', 253, 1315), ('best', 245, 931), ('story', 229, 1555), ('many', 203, 901), ('world', 201, 729), ('love', 200, 800), ('first', 166, 1318)]\n"
     ]
    }
   ],
   "source": [
    "print(_positive_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Explanation (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code I am looping through each review in the training data whilst giving myself access to the wordlist and the label. \n",
    "\n",
    "On the all word lists I preprocess and normalise accounting for case, numbers, punctuation and stopwords. I am doing this to remove noise and get access to the words in their cleanest and more contextualised form and removing words devoid of meaningful context. I did not implement any stemming or lemmanisation as the goal is to obtain a word list, hence, readabliltiy is desired. \n",
    "\n",
    "After which I push the wordlists into pre-initalised world lists for each label. It is important to have seperate DistFreqs for the label because I want to compare the frequency between the two. \n",
    "\n",
    "For each word I calculate two metrics. The differential between the positive and negative counts, as well as, the cumulative word count for the corupus.\n",
    "\n",
    "Words that come out with a positive differential are candiates for the positive world list, and negative ones the negative word list.\n",
    "\n",
    "The cumulative word count is used to identify words that appear to be domain stop words. That is, words that appear to be disproporionately used in context of writing reviews. The frequency of these words in the domain of reviewing means they loose the context they might otherwise hold in general terms. I remove these words as candidates for the word list.\n",
    "\n",
    "Finally, the word list is sorting by the index [1] which is the word differential metric. Slices of the top and bottom 10 are taken which are the words that are most skewed towards being in positive or negative reviews, hence, should be highly representative of sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word List Classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TApOQE6vND20"
   },
   "source": [
    "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
    "\n",
    "b) **Explain** what you have done.\n",
    "\n",
    "[12.5\\%]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BThDMrcmODJy"
   },
   "outputs": [],
   "source": [
    "# get review\n",
    "# set up empty freq dist for pos and neg (or convert list into freqdist)\n",
    "# loop through words and allocate counts for pos or neg freq\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_weight_converter(sentiment_word_list: list):\n",
    "    \"\"\"\n",
    "    Takes a sentiment word list with frequency counts converts it into a Sentiment Polarity weightings.  \n",
    "\n",
    "    Args:\n",
    "        sentiment_word_list (Iterable): Nested word list comprised of word:string, differential: int and total:int. \n",
    "        \n",
    "    Returns:\n",
    "        dict: dictionary of word and its sentiment weighting\n",
    "    \"\"\"\n",
    "    sentiment_weights = {\n",
    "        word: differential / total_usage\n",
    "        for word, differential, total_usage in sentiment_word_list\n",
    "    }\n",
    "\n",
    "    return sentiment_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'life': 0.29559748427672955, 'also': 0.23440860215053763, 'great': 0.3157262905162065, 'well': 0.19239543726235742, 'best': 0.2631578947368421, 'story': 0.1472668810289389, 'many': 0.2253052164261931, 'world': 0.2757201646090535, 'love': 0.25, 'first': 0.125948406676783}\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_weight_converter(_positive_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bad': -0.47695390781563124, 'plot': -0.23461538461538461, 'nothing': -0.2756756756756757, 'worst': -0.6780487804878049, 'script': -0.23827392120075047, 'stupid': -0.6551724137931034, 'boring': -0.5794871794871795, 'least': -0.23937360178970918, 'harry': -0.6441717791411042, 'supposed': -0.47085201793721976}\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_weight_converter(_negative_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "C6vK5Vyz2XUF"
   },
   "outputs": [],
   "source": [
    "from nltk.classify.api import ClassifierI\n",
    "import random\n",
    "\n",
    "class ReviewClassifer(ClassifierI):\n",
    "\n",
    "    def __init__(self, pos, neg):\n",
    "        self._pos = sentiment_weight_converter(pos)\n",
    "        self._neg = sentiment_weight_converter(neg)\n",
    "\n",
    "    def classify(self, words):\n",
    "        score = 0\n",
    "\n",
    "        for word in words:\n",
    "            \n",
    "            if word in self._pos:\n",
    "                score += self._pos[word]\n",
    "                print(word, self._pos[word])\n",
    "                print(\"SCORE:\", score)\n",
    "\n",
    "            elif word in self._neg:\n",
    "                score += self._neg[word]\n",
    "                print(word, self._neg[word])\n",
    "                print(\"SCORE:\", score)\n",
    "\n",
    "        print(\"SCORE:\", score)\n",
    "       \n",
    "        return \"neg\" if score < 0 else \"pos\"\n",
    "\n",
    "    def labels(self):\n",
    "        return (\"pos\", \"neg\")\n",
    "\n",
    "#Example usage:\n",
    "\n",
    "classifier = ReviewClassifer(_positive_word_list, _negative_word_list)\n",
    "# classifier.classify(\"This is an bad awful movie movie\".split())\n",
    "# classifier.classify(preprocess_text(training_data[0][0], stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well 0.19239543726235742\n",
      "SCORE: 0.19239543726235742\n",
      "story 0.1472668810289389\n",
      "SCORE: 0.33966231829129634\n",
      "great 0.3157262905162065\n",
      "SCORE: 0.6553886088075028\n",
      "story 0.1472668810289389\n",
      "SCORE: 0.8026554898364417\n",
      "great 0.3157262905162065\n",
      "SCORE: 1.1183817803526481\n",
      "plot -0.23461538461538461\n",
      "SCORE: 0.8837663957372635\n",
      "plot -0.23461538461538461\n",
      "SCORE: 0.6491510111218788\n",
      "story 0.1472668810289389\n",
      "SCORE: 0.7964178921508177\n",
      "world 0.2757201646090535\n",
      "SCORE: 1.0721380567598713\n",
      "story 0.1472668810289389\n",
      "SCORE: 1.21940493778881\n",
      "story 0.1472668810289389\n",
      "SCORE: 1.366671818817749\n",
      "story 0.1472668810289389\n",
      "SCORE: 1.5139386998466877\n",
      "well 0.19239543726235742\n",
      "SCORE: 1.706334137109045\n",
      "great 0.3157262905162065\n",
      "SCORE: 2.0220604276252514\n",
      "story 0.1472668810289389\n",
      "SCORE: 2.16932730865419\n",
      "well 0.19239543726235742\n",
      "SCORE: 2.3617227459165475\n",
      "story 0.1472668810289389\n",
      "SCORE: 2.5089896269454863\n",
      "first 0.125948406676783\n",
      "SCORE: 2.6349380336222694\n",
      "best 0.2631578947368421\n",
      "SCORE: 2.8980959283591115\n",
      "also 0.23440860215053763\n",
      "SCORE: 3.132504530509649\n",
      "world 0.2757201646090535\n",
      "SCORE: 3.4082246951187027\n",
      "life 0.29559748427672955\n",
      "SCORE: 3.7038221793954325\n",
      "world 0.2757201646090535\n",
      "SCORE: 3.979542344004486\n",
      "love 0.25\n",
      "SCORE: 4.229542344004486\n",
      "world 0.2757201646090535\n",
      "SCORE: 4.505262508613539\n",
      "also 0.23440860215053763\n",
      "SCORE: 4.7396711107640765\n",
      "love 0.25\n",
      "SCORE: 4.9896711107640765\n",
      "love 0.25\n",
      "SCORE: 5.2396711107640765\n",
      "worst -0.6780487804878049\n",
      "SCORE: 4.561622330276272\n",
      "great 0.3157262905162065\n",
      "SCORE: 4.877348620792478\n",
      "plot -0.23461538461538461\n",
      "SCORE: 4.642733236177094\n",
      "life 0.29559748427672955\n",
      "SCORE: 4.938330720453823\n",
      "best 0.2631578947368421\n",
      "SCORE: 5.201488615190666\n",
      "boring -0.5794871794871795\n",
      "SCORE: 4.622001435703487\n",
      "well 0.19239543726235742\n",
      "SCORE: 4.814396872965844\n",
      "great 0.3157262905162065\n",
      "SCORE: 5.13012316348205\n",
      "best 0.2631578947368421\n",
      "SCORE: 5.393281058218893\n",
      "SCORE: 5.393281058218893\n"
     ]
    }
   ],
   "source": [
    "classifier = ReviewClassifer(_positive_word_list, _negative_word_list)\n",
    "\n",
    "for rev,label in training_data[100:101]:\n",
    "\n",
    "    # PREPROCESSING: case, number, punctuation, stopword\n",
    "    rev = preprocess_text(token_list=rev, stop_words=stop)\n",
    "\n",
    "    classifier.classify(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your proposed formula is essentially calculating the Sentiment Polarity (or bias) of the word.The Formula: Polarity ScoreLet:$D$ be the differential (negative usages - positive usages).$T$ be the total usage of the word (over all reviews).The weighting formula would be:$$\\text{Weighting Score} = \\frac{D}{T}$$\n",
    "\n",
    "This score will always range between $-1.0$ and $+1.0$:\n",
    "- A score close to $-1.0$ (like worst at $-0.678$) indicates a word that is highly specific to negative reviews—a strong sentiment signal.\n",
    "- A score close to $0.0$ (like plot at $-0.235$) indicates a word that is used more evenly across both positive and negative reviews, or is very common, meaning it's less predictive of pure sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive word appear to naturally have a higher word count\n",
    "\n",
    "where as negative words appear to have more words which are strongy negative\n",
    "\n",
    "hopefully in terms of classification this is even things out and make things more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZdDO_Y92XUH"
   },
   "source": [
    "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
    "\n",
    "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LQc8bsA2XUI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_i80ceP2XUJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbYwwhcs2XUL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVZp0N5J2XUL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIS9UpmJNEAp"
   },
   "source": [
    "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
    "\n",
    "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results.\n",
    "\n",
    "[12.5\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gwjig-Y12XUN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AUsYRMa2XUN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bytPkuHf2XUO"
   },
   "source": [
    "However, if your goal were to build a full-scale machine learning classifier (like the Naïve Bayes mentioned in your labs) where the feature space is very large and the focus is purely on classification accuracy, then lemmatization (which provides a real dictionary word) would be strongly recommended to reduce noise and aggregate related features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGDXaVDqOSfY"
   },
   "source": [
    "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions.\n",
    "\n",
    "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
    "\n",
    "[25\\%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlxoUthX2XUP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1L7mZ-k2XUQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFeOWIRm2XUQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VT82P88M2XUQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym-TGvYS2XUR"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
