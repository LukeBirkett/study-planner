{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BThZppujhxPX"
   },
   "source": [
    "# Applied Natural Language Processing 955G5\n",
    "## Computer Based Examination, 2024\n",
    "\n",
    "Remember, you can add cells and change their type (between code and text/markdown) as required to answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9XarARfLiFmE"
   },
   "outputs": [],
   "source": [
    "# update your candidate number here\n",
    "candidate_number = 11111111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hqv3rUCwgi2N"
   },
   "source": [
    "# Question 1 (50 marks)\n",
    "\n",
    "This Question is about Question Answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-apneMCEgh_o",
    "outputId": "0c7bed5f-165d-464e-d9dd-3b21347cb948"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lukebirkett/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lukebirkett/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### do not change the code in this cell\n",
    "# make sure you run this cell\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "sentences=[\"Dave Grohl is the founder of the rock band Foo Fighters, for which he is the lead singer, guitarist, and principal songwriter.\",\n",
    "           \"Wet Leg are a British indie rock group from the Isle of Wight, founded in 2019 by Rhian Teasdale and Hester Chambers.\",\n",
    "           \"Pink Floyd were founded in 1965 by Syd Barrett (guitar, lead vocals), Nick Mason (drums), Roger Waters (bass guitar, vocals) and Richard Wright (keyboards, vocals).\",\n",
    "           \"David Eric Grohl was born in Warren, Ohio, on January 14, 1969.\",\n",
    "           \"The rock band Foo Fighters headlined the Isle of Wight festival on Saturday, June 10th, 2006.\",\n",
    "           \"\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4Rr3uSFln8E"
   },
   "source": [
    "a) By following the steps below, build an inverted index for the sentences above. This will be a dictionary whose keys are tokens and whose values are indexes into the list of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Mtlq5jnmWWI"
   },
   "source": [
    "i) Tokenize the sentences and call the result `tokenized_sentences`. In other words, produce a list of lists of tokens, by turning each string in `sentences` into a list of tokens. For example: `[\"This is an example\",\"This is another\"]` would become `[[\"This\",\"is\",\"an\",\"example\"],[\"This\",\"is\",\"another\"]]`\n",
    "\n",
    "(4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9KaDiMqNmc-z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences = [word_tokenize(sent) for sent in sentences]\n",
    "len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6wvXf7l379g"
   },
   "source": [
    "ii) Case normalise the tokens in the sentences in the list tokenized_sentences and remove punctuation and stopwords.\n",
    "\n",
    "For example, `[[\"This\",\"is\",\"UPPER\",\"case\", \".\"]]` would become `[[\"upper\",\"case\"]]`.\n",
    "\n",
    "(6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eLtFE23C4YUs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['dave', 'grohl', 'founder', 'rock', 'band', 'foo', 'fighters', 'lead', 'singer', 'guitarist', 'principal', 'songwriter']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences_filtered = [\n",
    "    [t.lower() for t in sent if t.isalpha() and t.lower() not in stop]\n",
    "    for sent in tokenized_sentences\n",
    "]\n",
    "\n",
    "print(len(tokenized_sentences_filtered))\n",
    "print(tokenized_sentences_filtered[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeVGWyK5mdpk"
   },
   "source": [
    "iii) Construct a dictionary called `inverted_index` that allows us to lookup the the sentences it occurs in. In other words, for each token in the lists within `tokenized_sentences`, build up a list of the indexes of the sentences it occurs in. For example, \"lead\" occurs in sentences with indexes 0 and 2, so `inverted_index[\"lead\"]` has the value `[0,2]`\n",
    "\n",
    "(10 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vxYpuaTKrDXg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'band': [0, 4], 'grohl': [0, 3], 'songwriter': [0], 'founder': [0], 'rock': [0, 1, 4], 'dave': [0], 'foo': [0, 4], 'guitarist': [0], 'singer': [0], 'principal': [0], 'fighters': [0, 4], 'lead': [0, 2], 'wet': [1], 'chambers': [1], 'isle': [1, 4], 'teasdale': [1], 'british': [1], 'wight': [1, 4], 'founded': [1, 2], 'indie': [1], 'rhian': [1], 'leg': [1], 'group': [1], 'hester': [1], 'roger': [2], 'mason': [2], 'syd': [2], 'pink': [2], 'barrett': [2], 'vocals': [2], 'floyd': [2], 'nick': [2], 'drums': [2], 'keyboards': [2], 'richard': [2], 'bass': [2], 'wright': [2], 'guitar': [2], 'waters': [2], 'ohio': [3], 'january': [3], 'david': [3], 'warren': [3], 'eric': [3], 'born': [3], 'june': [4], 'festival': [4], 'headlined': [4], 'saturday': [4]}\n"
     ]
    }
   ],
   "source": [
    "def create_index(sentence_list):\n",
    "    index={}\n",
    "    for i,sent in enumerate(sentence_list):\n",
    "        words=set(sent)\n",
    "        for word in words:\n",
    "            current=index.get(word,[])\n",
    "            current.append(i)\n",
    "            index[word]=current\n",
    "    return index\n",
    "\n",
    "inverted_index = create_index(tokenized_sentences_filtered)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuRVaDy1sotr"
   },
   "source": [
    "b) An Information Retrieval system attempts to find relevant sentences to find bands that are from the Isle of Wight. It retrieves three sentences based on relevant keywords, but only one of those sentences contains an actual answer to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ufNcqCm5ttQS"
   },
   "outputs": [],
   "source": [
    "retrieved=[0,1,4]\n",
    "relevant =[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj_BptMUw0Dv"
   },
   "source": [
    "i) Write a function that returns the precision and recall of a retrieval system, given two inputs representing the sentences that were retrieved and the sentences that were actually relevant to the query. Each input will be a list of indices. Apply the function to the lists given above.\n",
    "\n",
    "(6 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Precision | Recall |\n",
    "| :--- | :--- | \n",
    "| Proportion of pos predictions that are actually correct | Proportion of actual pos documents that were predicted correctly | \n",
    "| $$\\frac{TP}{TP + FP}$$ | $$\\frac{TP}{TP + FN}$$ | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.3333333333333333, 'recall': 1.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_and_recall(ret,rel):\n",
    "    tp = len(set(ret) & set(rel)) # & = set intersection\n",
    "    fp = len(set(ret) - set(rel)) # present in ret, not in rel\n",
    "    fn = len(set(rel) - set(ret)) # present in rel, not in ret\n",
    "\n",
    "    prec_n = tp\n",
    "    prec_d = tp + fp\n",
    "\n",
    "    prec = 0 if tp == 0 else (prec_n / prec_d)\n",
    "\n",
    "    rec_n = tp\n",
    "    rec_d = tp + fn\n",
    "\n",
    "    rec = 0 if tp == 0 else (rec_n / rec_d) \n",
    "\n",
    "    return {\"precision\": prec, \"recall\":rec}\n",
    "\n",
    "pr = precision_and_recall(retrieved, relevant)\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM3NVu5ehq68"
   },
   "source": [
    "c) For each of the following questions, identify the answer type (i.e. in terms of a named entity tag such as PER, LOC or ORG) and the features of the question a system might use to predict these types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ8iNZzMhDra"
   },
   "source": [
    "i) \"Where was the lead singer of the Foo Fighters born?\" (2 marks)\n",
    "\n",
    "- TAG: LOC/Location\n",
    "- FEATURES: Where, born (verb)\n",
    "\n",
    "ii) \"Which band are from the Isle of Wight?\" (2 marks)\n",
    "\n",
    "- TAG: ORG/ORGANISATION\n",
    "- FEATURES: Which, band (noun)\n",
    "\n",
    "iii) \"Who founded Pink Floyd?\" (2 marks)\n",
    "\n",
    "- TAG: PER/PERSON\n",
    "- FEATURES: Who, founded (verb)\n",
    "\n",
    "I have included the interrogative word as the primary feature and a secondary noun or verb which cements the answer types. Looking at the occurence of these pairs would cement the answer to a higher degree of certainty. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o411W8cN1CKZ"
   },
   "source": [
    "iv) Why might it be difficult to retrieve the relevant sentence to answer the question about the band from the Isle of Wight from your inverted index? How might WordNet be used to make this more effective?\n",
    "\n",
    "(4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4W3DUWP2a2I"
   },
   "source": [
    "In its most basic implementation, an inverted index approach will use boolean keyword retrieval to match the query to documents/sentence. Even if we are able to indentify that we are looking for a \"BAND\", the sentence which answers our question refers the entity as a group, meaning our inverted index will not send us to that sentence for interogation. This is a case of vocabulary mismatch. The use of WordNet would be able to make our approach more effective because once we identify we are looking for a \"BAND\" we can use WordNet to identify relevant sense's (synset) which would hopefully cover \"GROUP\" and a possibly synonym. This would allow us to update the query that searches to inverted index to (\"BAND\" or \"GROUP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsjHtTzX2bRw"
   },
   "source": [
    "v) What difficulties are involved in answering the question \"Where was the lead singer of the Foo Fighters born?\" from the set of sentences above?\n",
    "\n",
    "(5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NURddwNk4N0Q"
   },
   "source": [
    "- The answer to the question is spread accross two sentences\n",
    "- You need sentence[0] to identify that Dave Grohl is the lead singer of the entity Foo Fighters.\n",
    "- Then you need sentence[3] to understand that David Eric Grohl was born in Ohio\n",
    "- \"David Eric Grohl\" is a different alias to what we saw in the other sentence. \n",
    "- The sentence only tells us he was born in Ohio. If we wanted less granularity and just the country, neither this sentence, nor any of the otehr make this connection, meaning an external knowledge base would be needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDBfc47va3z8"
   },
   "source": [
    "vi) Define a function that takes two terms as input and returns a list of terms that connect them. In particular, use your inverted index to find the sentences that each of the input terms occurs in and then find terms that occur in both sets of sentences, i.e. occur in a sentence with the first term and also occur in a sentence with the second term.\n",
    "\n",
    "The output of your function should be a list of tuples containing the index of the sentence containing the first term, the index of the sentence containing the second term and the third term that occurs in both sentences.\n",
    "\n",
    "So, for example, the term `\"leg\"` occurs in sentence `1` and `\"headlined\"` occurs in sentence `4`. The terms `\"rock\"`, `\"isle\"` and `\"wight\"` also occur in both those sentences connecting them. So, given the inputs `\"leg\"` and `\"headlined\"` your function should return `[(1, 4, 'rock'), (1, 4, 'isle'), (1, 4, 'wight')]`.\n",
    "\n",
    "Apply this function to the terms `\"foo\"` and `\"born\"`.\n",
    "\n",
    "(9 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use inputs to ret lists from the index\n",
    "2. Count the lengths of each list\n",
    "3. Construct a nested loop with 1 list as the outer and the other as the inner using enumerate to get the index, text. Note text will need to be accessed using the inversted index doc IDs, it wont give text directly.\n",
    "4. At end inner iteration this will result in two lists of words.\n",
    "5. Set intersect the lists `&` to identify the common words. \n",
    "6. Remove input terms from list\n",
    "7. loop though the common words adding a tuple of (index_outer, index_inner, \"common_word\") to a pre loop initalise list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIERvrA3a82k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grohl\n",
      "[(0, 3, 'grohl')]\n"
     ]
    }
   ],
   "source": [
    "def connector(input1, input2, iindex, text):\n",
    "    list1 = iindex.get(input1, [])\n",
    "    list2 = iindex.get(input2, []) \n",
    "\n",
    "    if len(list1) == 0 or len(list2) == 0:\n",
    "        return []\n",
    "\n",
    "    cons = []\n",
    "\n",
    "    for i,sent_1 in enumerate(list1):\n",
    "        words_1 = set(text[sent_1])\n",
    "        for j,sent_2 in enumerate(list2):\n",
    "            words_2 = set(text[sent_2])\n",
    "\n",
    "            shared = words_1 & words_2\n",
    "\n",
    "            if len(shared) > 0:\n",
    "                for shared_word in shared:\n",
    "                    cons.append((sent_1,sent_2,shared_word))\n",
    "    \n",
    "    return cons\n",
    "\n",
    "print(connector(\"foo\", \"born\", inverted_index, tokenized_sentences_filtered))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
